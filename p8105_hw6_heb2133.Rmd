---
title: "Homework 6"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in and prepare data:

Created city_state variable and binary 'solved/unsolved' homicide variable indicating whether the homicide is solved. Limited analysis to those for whom victim_race is white or black.

```{r}
homicide_df = 
  read.csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  janitor::clean_names() %>% 
  # add city_state variable
  unite("city_state", city:state, sep = ", ", remove = TRUE) %>%
  # add homicide solved variable 
  mutate(
    resolved = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1),
    victim_age = as.numeric(victim_age)
  ) %>% 
  # omit Dallas, Phoenix, Kansas City, and Tulsa, AZ
  filter(city_state != "Dallas, TX", city_state != "Phoenix, AZ", city_state != "Kansas City, MO", city_state != "Tulsa, AL") %>% 
  filter(victim_race %in% c("White", "Black")) %>% 
  # changing reference group so that OR in log reg models are 
  # comparing Black victims to white victims 
  mutate(victim_race = fct_relevel(victim_race, "White", "Black"))
```

Baltimore, MD - logistic regression model with resolved vs unresolved as outcome and victim age, sex and race as predictors.

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolved ~ victim_age + victim_sex + victim_race, 
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 4)
```

The estimated odds of resolving homicides in Baltimore for Black victims is 0.43 times the odds of resolved homicides for white victims. We are 95% confident that this OR lies between 0.31 and 0.61.

Run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing Black victims to white victims. 

```{r}
model_resuls_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, 
          ~glm(resolved ~ victim_age + victim_sex + victim_race, 
               data = .x, 
               family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
    mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))

# Extracted OR for each city comparing homicide 
# resolution for Black victims compared to white victims

model_resuls_df %>% 
  filter(term == "victim_raceBlack") %>% 
  knitr::kable(digit = 4)
```

Plot that shows estimated ORs and CIs for each city (OR of resolution Male vs Female homicide victims)

```{r}
model_resuls_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text = element_text(angle = 90, hjust = 1))
```

From this plot we can see that the majority of OR estimates are less than 1, meaning that homicides with male victims generally have lower odds of being resolved by arrest. 

## Problem 2

Read and clean birthweight dataset: 

```{r}
bw_df =
  read.csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    mrace = case_when(
      mrace == 1      ~ "white",
      mrace == 2      ~ "black",
      mrace == 3     ~ "asian",
      mrace == 4      ~ "peurto rican",
      mrace == 8      ~ "other")
    ) %>% 
  mutate(
    mrace = fct_relevel(mrace, "white")
  )

# Checking for missing values
any(is.na(bw_df))
```

Propose model for birthweight:

The hypothesized predictors that I wanted to explore in their potential contribution to birthweight are: 1) Gestational age 2) Maternal race 3) Family monthly income 4) Mother's weight gain during pregnancy and 5) Mother's age at delivery. Knowing that gestational age does have an impact on infant birthweight, I wanted to also introduce and examine predictors that brought in environmental or socio-demographic factors - like mother's race and family SES (using family income in this dataset). I used white mothers as the reference group in this model. 

Looking at the density plot below examining the residuals for this model, it looks fairly normally distributed. 

```{r}
proposed_model_df = 
  lm(bwt ~ gaweeks + wtgain + fincome + momage + mrace, data = bw_df)

broom::glance(proposed_model_df)

broom::tidy(proposed_model_df) %>% 
  select(term, estimate, std.error, p.value) %>% 
  knitr::kable(digit = 4)

bw_df %>% 
  add_predictions(proposed_model_df) %>% 
  add_residuals(proposed_model_df) %>% 
  ggplot(aes(x = pred, y = resid))+
  geom_point()

bw_df %>% 
  add_residuals(proposed_model_df) %>% 
  ggplot(aes(x = resid))+ 
  geom_density()
```

Comparing proposed model to two others:

1. Using length at birth and gestational age as predictors (main effects only)
2. Using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
main_eff_model = lm(bwt ~ blength + gaweeks, 
                    data = bw_df)

interaction_model = lm(bwt ~ bhead + blength + babysex + 
                         bhead*blength + bhead*babysex + blength*babysex +
               bhead*blength*babysex, 
               data = bw_df)

cross_df = 
  crossv_mc(bw_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cross_df = 
  cross_df %>% 
  mutate(
    proposed_model_df = map(.x = train, 
                            ~lm(bwt ~ gaweeks + wtgain + fincome + 
                                  momage + mrace, 
                                data = .x)),
    main_eff_model = map(.x = train,
                         ~lm(bwt ~ blength + gaweeks, data = .x)),
    interaction_model = map(.x = train,
                            ~lm(bwt ~ bhead + blength + babysex + 
                                  bhead*blength + bhead*babysex + blength*babysex +
                                  bhead*blength*babysex,
                                data = .x))
  ) %>% 
  mutate(
    rmse_proposed = 
      map2_dbl(.x = proposed_model_df, .y = test, 
               ~rmse(model = .x, data = .y)),
    rmse_main_eff = 
      map2_dbl(.x = main_eff_model, .y = test,
               ~rmse(model = .x, data = .y)),
    rmse_interaction = 
      map2_dbl(.x = interaction_model, .y = test, 
               ~rmse(model = .x, data = .y))
  )

cross_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
    ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin(
  )
```

By looking at the above violin plots, we can see that model 3 (the interaction model) has the lowest RMSE and so has the greatest prediction accuracy. My proposed model, of the three, has the highest RMSE and so has the least prediction accuracy. 

## Problem 3