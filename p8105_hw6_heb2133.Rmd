---
title: "Homework 6"
output: github_document
---

```{r}
library(tidyverse)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in and prepare data:

Created city_state variable and binary 'solved/unsolved' homicide variable indicating whether the homicide is solved. Limited analysis to those for whom victim_race is white or black.

```{r}
homicide_df = 
  read.csv("./data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  janitor::clean_names() %>% 
  # add city_state variable
  unite("city_state", city:state, sep = ", ", remove = TRUE) %>%
  # add homicide solved variable 
  mutate(
    resolved = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1),
    victim_age = as.numeric(victim_age)
  ) %>% 
  # omit Dallas, Phoenix, Kansas City, and Tulsa, AZ
  filter(city_state != "Dallas, TX", city_state != "Phoenix, AZ", city_state != "Kansas City, MO", city_state != "Tulsa, AL") %>% 
  filter(victim_race %in% c("White", "Black")) %>% 
  # changing reference group so that OR in log reg models are 
  # comparing Black victims to white victims 
  mutate(victim_race = fct_relevel(victim_race, "White", "Black"))
```

Baltimore, MD - logistic regression model with resolved vs unresolved as outcome and victim age, sex and race as predictors.

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "Baltimore, MD")

glm(resolved ~ victim_age + victim_sex + victim_race, 
    data = baltimore_df, 
    family = binomial()) %>% 
  broom::tidy() %>% 
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, OR, starts_with("CI")) %>% 
  knitr::kable(digits = 4)
```

The estimated odds of resolving homicides in Baltimore for Black victims is 0.43 times the odds of resolved homicides for white victims. We are 95% confident that this OR lies between 0.31 and 0.61.

Run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing Black victims to white victims. 

```{r}
model_resuls_df = 
  homicide_df %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = 
      map(.x = data, 
          ~glm(resolved ~ victim_age + victim_sex + victim_race, 
               data = .x, 
               family = binomial())),
    results = map(models, broom::tidy)
  ) %>% 
  select(city_state, results) %>% 
  unnest(results) %>% 
    mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, OR, starts_with("CI"))

# Extracted OR for each city comparing homicide 
# resolution for Black victims compared to white victims

model_resuls_df %>% 
  filter(term == "victim_raceBlack") %>% 
  knitr::kable(digit = 4)
```

Plot that shows estimated ORs and CIs for each city (OR of resolution Male vs Female homicide victims)

```{r}
model_resuls_df %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text = element_text(angle = 90, hjust = 1)) + 
  labs(title = "OR for homicide resolution among male versus female victims")
```

From this plot we can see that the majority of OR estimates are less than 1, meaning that homicides with male victims generally have lower odds of being resolved by arrest. 

## Problem 2

Read and clean birthweight dataset: 

```{r}
bw_df =
  read.csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    mrace = as.factor(mrace),
    mrace = case_when(
      mrace == 1      ~ "white",
      mrace == 2      ~ "black",
      mrace == 3     ~ "asian",
      mrace == 4      ~ "peurto rican",
      mrace == 8      ~ "other")
    ) %>% 
  mutate(
    mrace = fct_relevel(mrace, "white")
  )

# Checking for missing values
any(is.na(bw_df))
```

Propose model for birthweight:

The hypothesized predictors that I wanted to explore in their potential contribution to birthweight are: 1) Gestational age 2) Maternal race 3) Family monthly income 4) Mother's weight gain during pregnancy and 5) Mother's age at delivery. Knowing that gestational age does have an impact on infant birthweight, I wanted to also introduce and examine predictors that brought in environmental or socio-demographic factors - like mother's race and family SES (using family income in this dataset). I used white mothers as the reference group in this model. 

```{r}
proposed_model_df = 
  lm(bwt ~ gaweeks + wtgain + fincome + momage + mrace, data = bw_df)

broom::glance(proposed_model_df)

broom::tidy(proposed_model_df) %>% 
  select(term, estimate, std.error, p.value) %>% 
  knitr::kable(digit = 4)

bw_df %>% 
  add_predictions(proposed_model_df) %>% 
  add_residuals(proposed_model_df) %>% 
  ggplot(aes(x = pred, y = resid))+
  geom_point() + 
  labs(title = "Modeling residuals against fitted 'predicted' values")

bw_df %>% 
  add_residuals(proposed_model_df) %>% 
  ggplot(aes(x = resid))+ 
  geom_density() +
  labs (title = "overall distribution of residuals")

bw_df %>% 
  add_residuals(proposed_model_df) %>% 
  ggplot(aes (x = mrace, y = resid)) + 
  geom_violin() + 
  labs(title = "distribution of residuals for maternal race categories")
```

After making a scatter plot comparing the residuals against predicted valus for this model, I also made a density plot to get a better view of how the residuals were behaving  - which looks fairly normally distributed. I also wanted to make a violin plot comparing the distribution of residuals for each category of maternal race, as it's the only categorical variable in the model - which, overall, don't look too skewed. 

Comparing proposed model to two others:

1. Using length at birth and gestational age as predictors (main effects only)
2. Using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
main_eff_model = lm(bwt ~ blength + gaweeks, 
                    data = bw_df)

interaction_model = lm(bwt ~ bhead + blength + babysex + 
                         bhead*blength + bhead*babysex + blength*babysex +
               bhead*blength*babysex, 
               data = bw_df)

cross_df = 
  crossv_mc(bw_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cross_df = 
  cross_df %>% 
  mutate(
    proposed_model_df = map(.x = train, 
                            ~lm(bwt ~ gaweeks + wtgain + fincome + 
                                  momage + mrace, 
                                data = .x)),
    main_eff_model = map(.x = train,
                         ~lm(bwt ~ blength + gaweeks, data = .x)),
    interaction_model = map(.x = train,
                            ~lm(bwt ~ bhead + blength + babysex + 
                                  bhead*blength + bhead*babysex + blength*babysex +
                                  bhead*blength*babysex,
                                data = .x))
  ) %>% 
  mutate(
    rmse_proposed = 
      map2_dbl(.x = proposed_model_df, .y = test, 
               ~rmse(model = .x, data = .y)),
    rmse_main_eff = 
      map2_dbl(.x = main_eff_model, .y = test,
               ~rmse(model = .x, data = .y)),
    rmse_interaction = 
      map2_dbl(.x = interaction_model, .y = test, 
               ~rmse(model = .x, data = .y))
  )

cross_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
    ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin() + 
  labs(title = "comparing model RMSE")
```

By looking at the above violin plots, we can see that model 3 (the interaction model) has the lowest RMSE and so has the greatest prediction accuracy. My proposed model, of the three, has the highest RMSE and so has the least prediction accuracy. 

## Problem 3

Reading in weather data:

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Focusing on simple linear regression with tmax as the response and tmin as the predictor. 

```{r}
weather_model_df = 
  lm(tmax ~ tmin, data = weather_df)
```

Getting quantities of r^2 and log(β0∗β1) using 5000 bootstrap sample:

```{r}

boot_sample = function(df) {
  
  sample_frac(df, replace = TRUE)
  
}

boot_strap =
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_results = 
  boot_strap %>% 
  mutate(
    models = map(.x = strap_sample,
                 ~lm(tmax ~ tmin, 
                     data = .x)),
    results_r = map(models, broom::glance),
    results_log = map(models, broom::tidy)
  ) %>% 
  select(strap_number, results_r, results_log) %>% 
  unnest(results_r, results_log) %>% 
  select(strap_number, term, estimate, r.squared)

# cleaning up for plots and final estimates
boot_results_clean = 
  boot_results %>% 
    pivot_wider(
               names_from = term,
               values_from = estimate
               ) %>% 
  rename("intercept" = "(Intercept)") %>% 
  mutate(
    log_est = log(intercept*tmin)
  ) %>% 
  select(-intercept, -tmin)
```

Plotting distribution of estimates: 

```{r}
boot_results_clean %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  labs(title = "distribution of r^2 from boot strap samples")

boot_results_clean %>% 
  ggplot(aes(x = log_est)) + 
  geom_density() + 
  labs(title = "distribution of loglog(β0*β1) from boot strap samples",
       x = "log(β0*β1")
```

The above plots demonstrate the distribution of r^ 2 and log(β0∗β1) from 5000 bootstrap samples of our weather data. From these plots, we can see that these terms are relatively normally distributed. The average of the r^2 terms from these samples seems to be around 9.1. The average of our log(β0∗β1) terms from these samples seems to be between 2.00-2.025. 